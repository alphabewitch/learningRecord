# Survey on Efficient Training of Large Neural Networks

## 01 背景介绍

现代深度神经网络DNN需要大量的内存来存储训练期间的权重、激活值和其他中间标量。**本文分析了在具有单个或多个GPU的架构上节省内存并很好地利用计算、通信资源的技术。**

本调查中要解决的问题：基于你的模型和你的计算平台，有哪些通用的方法可以让你有效地进行训练。

下标描述了不同的技术对通信、内存、计算效率的影响：

<img src="img/Survey on Efficient Training of Large Neural Networks/image-20230522153255659.png" alt="image-20230522153255659" style="zoom:200%;" />

所调查的技术包括**①重计算、②卸载、③近似优化器状态和梯度、④数据并行、⑤模型并行、⑥管道并行**

## 02 减少单个GPU上显存占用

神经网络在前向传递期间，会产生大量的激活值占据大量的显存。有两种方法减少显存占用：① 重计算（checkpointing）、② 卸载（Offloading）。

### 1、checkpointing

前向传播过程中只存储一部分激活值，在后向传递过程中重新计算其余部分。

检查点方法可以通过它们处理的计算图来区分：

1. 为**同构顺序网络**找到最佳调度；
2. 对于过渡模型，如**异构顺序网络；**
3. **一般图**

### 2、Offloading of Activations

在前向传递过程中将激活卸载到CPU主存，并将其与取回GPU显存来用于相应的后向计算。但是主存、显存之间的传输会受到PCI总线带宽限制，所以要选择传输哪些激活值和何时传输激活值。

### 3、Offloading of weights



## 03 并行训练





## 04 优化器



